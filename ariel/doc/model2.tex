\section{Inferring the Absolute Magnitude of an Individual Galaxy from its Rotation Velocity}
\label{sec:infer_single_galaxy_y}

Assume we have already fit the TF model to a sample and obtained the posterior
\begin{equation}
p(\theta \mid \{\hat x_i,\hat y_i\}_{i=1}^N),
\qquad
\theta \equiv (s,c,\sigma_{\text{int},x},\sigma_{\text{int},y}).
\end{equation}
We now consider a \emph{new} galaxy, denoted by ``$\star$'', for which we measure a rotation-velocity proxy
$\hat x_\star$ with uncertainty $\sigma_{x,\star}$, and we wish to infer its true absolute magnitude $y_\star$
(or predict what absolute magnitude we should expect given $\hat x_\star$ and the TF calibration).

\subsection{Posterior predictive distribution}
The desired quantity is the posterior predictive distribution
\begin{equation}
p(y_\star \mid \hat x_\star, \sigma_{x,\star}, \{\hat x_i,\hat y_i\})
=
\int d\theta\;
p\!\left(y_\star \mid \hat x_\star, \sigma_{x,\star}, \theta\right)\,
p\!\left(\theta \mid \{\hat x_i,\hat y_i\}\right).
\label{eq:posterior_predictive_y}
\end{equation}
In practice, if we have posterior draws $\{\theta^{(m)}\}_{m=1}^M$, the integral is approximated by a mixture
\begin{equation}
p(y_\star \mid \hat x_\star, \cdots)\;\approx\; \frac{1}{M}\sum_{m=1}^M
p\!\left(y_\star \mid \hat x_\star, \sigma_{x,\star}, \theta^{(m)}\right).
\end{equation}

\subsection{Closed form when $p(y_{\text{TF}})$ is uniform on $\mathbb{R}$}
Adopt the same generative structure as in \S\ref{sec:model}, and define
\begin{equation}
\sigma_{1,\star}^2 \equiv \sigma_{x,\star}^2 + \sigma_{\text{int},x}^2,
\end{equation}
so that (after marginalizing over the latent true $x_\star$)
\begin{equation}
\hat x_\star \mid y_{\text{TF},\star},\theta \sim
\mathcal N\!\left(\frac{y_{\text{TF},\star}-c}{s},\ \sigma_{1,\star}\right),
\qquad
y_\star \mid y_{\text{TF},\star},\theta \sim \mathcal N\!\left(y_{\text{TF},\star},\ \sigma_{\text{int},y}\right).
\end{equation}
If we take $p(y_{\text{TF},\star})\propto 1$ on $\mathbb{R}$, then the conditional distribution of the latent
on-relation magnitude is
\begin{equation}
y_{\text{TF},\star}\mid \hat x_\star,\theta \sim
\mathcal N\!\left(c+s\,\hat x_\star,\ |s|\,\sigma_{1,\star}\right).
\end{equation}
Marginalizing over $y_{\text{TF},\star}$ yields a simple Gaussian predictive distribution for the galaxy's true
absolute magnitude:
\begin{equation}
y_\star \mid \hat x_\star,\sigma_{x,\star},\theta \sim
\mathcal N\!\left(
c+s\,\hat x_\star,\ \sigma_{y\mid x,\star}
\right),
\qquad
\sigma_{y\mid x,\star}^2 \equiv s^2\,\sigma_{1,\star}^2 + \sigma_{\text{int},y}^2.
\label{eq:y_given_xhat}
\end{equation}
Thus, for a fixed parameter vector $\theta$, the TF-based point prediction and uncertainty are
\begin{equation}
\mathbb E[y_\star \mid \hat x_\star,\theta] = c+s\,\hat x_\star,
\qquad
\text{Var}(y_\star \mid \hat x_\star,\theta)= s^2(\sigma_{x,\star}^2+\sigma_{\text{int},x}^2)+\sigma_{\text{int},y}^2.
\end{equation}


\subsection{Top-Hat Model for $y_{\text{TF},i}$}
In \S\ref{sec:simple_noPV}, we considdered a model with a uniform prior on $y_{\text{TF}}$ over a finite interval $[y_{\min},y_{\max}]$.
For consistency, the inferred posterior for $y_{\text{TF},\star}$ is then
\begin{equation}
y_{\text{TF},\star}\mid \hat x_\star,\theta
\ \propto\
\mathcal N\!\left(\hat x_\star;\frac{y_{\text{TF},\star}-c}{s},\sigma_{1,\star}\right)\,
\mathbf{1}\{y_{\min}\le y_{\text{TF},\star}\le y_{\max}\},
\end{equation}
i.e. a truncated normal distribution with (untruncated) location $c+s\hat x_\star$ and scale $|s|\sigma_{1,\star}$.
The resulting $p(y_\star\mid \hat x_\star,\theta)$ is no longer exactly Gaussian because it is the convolution of a
truncated normal ($y_{\text{TF}}$) with a normal ($y_\star\mid y_{\text{TF}}$).

To characterize the posterior predictive distribution, a convenient approach is to use
Monte Carlo composition, conditional on each posterior draw $\theta^{(m)}$:
\begin{align}
y_{\text{TF},\star}^{(m,k)} &\sim \text{TruncNormal}\!\left(c^{(m)}+s^{(m)}\hat x_\star,\ |s^{(m)}|\sigma_{1,\star}^{(m)};\ [y_{\min},y_{\max}]\right),\\
y_{\star}^{(m,k)} &\sim \mathcal N\!\left(y_{\text{TF},\star}^{(m,k)},\ \sigma_{\text{int},y}^{(m)}\right),
\end{align}
and then pool $\{y_{\star}^{(m,k)}\}$ over $(m,k)$ to obtain posterior means and credible intervals.

\subsection{Normal Model for $y_{\text{TF},i}$}
Assume the latent on-relation magnitude has a Gaussian population distribution,
\begin{equation}
y_{\text{TF}} \sim \mathcal N(\mu_{\text{TF}},\tau),
\end{equation}
where $\tau$ is the standard deviation. As above, define
\begin{equation}
\sigma_{1,\star}^2 \equiv \sigma_{x,\star}^2+\sigma_{\text{int},x}^2,
\end{equation}
so that the $\hat x_\star$ likelihood given $y_{\text{TF},\star}$ is
\begin{equation}
\hat x_\star \mid y_{\text{TF},\star},\theta \sim
\mathcal N\!\left(\frac{y_{\text{TF},\star}-c}{s},\ \sigma_{1,\star}\right).
\end{equation}
Equivalently, viewed as a likelihood in $y_{\text{TF},\star}$, this is
\begin{equation}
p(\hat x_\star\mid y_{\text{TF},\star},\theta)
\ \propto\
\exp\!\left[-\frac{(y_{\text{TF},\star}-(c+s\hat x_\star))^2}{2\,s^2\sigma_{1,\star}^2}\right],
\end{equation}
i.e.
\begin{equation}
y_{\text{TF},\star}\ \text{``measured by''}\ \hat x_\star
\quad\text{with}\quad
y_{\text{TF},\star}\approx c+s\hat x_\star,\ \ \text{sd}=|s|\sigma_{1,\star}.
\end{equation}

\paragraph{Posterior for $y_{\text{TF},\star}$ (conjugate normal-normal).}
Combining the normal prior $y_{\text{TF},\star}\sim \mathcal N(\mu_{\text{TF}},\tau)$ with the (normal-in-$y_{\text{TF}}$) likelihood implied by $\hat x_\star$ yields
\begin{equation}
y_{\text{TF},\star}\mid \hat x_\star,\sigma_{x,\star},\theta,\mu_{\text{TF}},\tau
\sim \mathcal N\!\left(\mu_{\text{post}},\ \sigma_{\text{post}}\right),
\end{equation}
with
\begin{align}
\sigma_{\text{post}}^2
&=
\left(\frac{1}{\tau^2}+\frac{1}{s^2\sigma_{1,\star}^2}\right)^{-1},\\[3pt]
\mu_{\text{post}}
&=
\sigma_{\text{post}}^2
\left(
\frac{\mu_{\text{TF}}}{\tau^2}
+
\frac{c+s\hat x_\star}{s^2\sigma_{1,\star}^2}
\right).
\end{align}
This shows explicitly the shrinkage toward $\mu_{\text{TF}}$: the posterior mean is an inverse-variance--weighted average of $\mu_{\text{TF}}$ and $c+s\hat x_\star$.

To characterize the posterior predictive distribution, a convenient approach is to use
Monte Carlo composition, conditional on each posterior draw $\theta^{(m)}$:
\begin{align}
y_{\text{TF},\star}^{(m,k)} &\sim \text{TruncNormal}\!\left(c^{(m)}+s^{(m)}\hat x_\star,\ |s^{(m)}|\sigma_{1,\star}^{(m)};\ [y_{\min},y_{\max}]\right),\\
y_{\star}^{(m,k)} &\sim \mathcal N\!\left(y_{\text{TF},\star}^{(m,k)},\ \sigma_{\text{int},y}^{(m)}\right),
\end{align}
and then pool $\{y_{\star}^{(m,k)}\}$ over $(m,k)$ to obtain posterior means and credible intervals.
